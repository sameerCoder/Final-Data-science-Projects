{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k Nearest Neighbours with Python and Scikit-Learn\n",
    "\n",
    "\n",
    "k Nearest Neighbours is a very simple and one of the topmost machine learning algorithms. In this project, I build a k Nearest Neighbours classifier to classify the patients suffering from Breast Cancer. I have used the `Breast Cancer Wisconsin (Original) Data Set` downloaded from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "1.\tIntroduction to k Nearest Neighbours Algorithm\n",
    "2.\tk Nearest Neighbours intuition\n",
    "3.\tThe problem statement\n",
    "4.\tDataset description\n",
    "5.\tImport libraries\n",
    "6.\tImport dataset\n",
    "7.\tExploratory data analysis\n",
    "8.\tData visualization\n",
    "9.\tDeclare feature vector and target variable\n",
    "10.\tSplit data into separate training and test set\n",
    "11.\tFeature engineering\n",
    "12.\tFeature scaling\n",
    "13.\tFit Neighbours classifier to the training set\n",
    "14.\tPredict the test-set results\n",
    "15.\tCheck the accuracy score\n",
    "16.\tRebuild kNN classification model using different values of k\n",
    "17.\tConfusion matrix\n",
    "18.\tClassification metrices\n",
    "19.\tROC - AUC\n",
    "20.\tk-Fold Cross Validation\n",
    "21.\tResults and conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to k Nearest Neighbours algorithm\n",
    "\n",
    "\n",
    "\n",
    "In machine learning, k Nearest Neighbours or kNN is the simplest of all machine learning algorithms. It is a non-parametric algorithm used for classification and regression tasks. Non-parametric means there is no assumption required for data distribution. So, kNN does not require any underlying assumption to be made. In both classification and regression tasks, the input consists of the k closest training examples in the feature space. The output depends upon whether kNN is used for classification or regression purposes.\n",
    "\n",
    "-\tIn kNN classification, the output is a class membership. The given data point is classified based on the majority of type of its neighbours. The data point is assigned to the most frequent class among its k nearest neighbours. Usually k is a small positive integer. If k=1, then the data point is simply assigned to the class of that single nearest neighbour.\n",
    "\n",
    "-\tIn kNN regression, the output is simply some property value for the object. This value is the average of the values of k nearest neighbours.\n",
    "\n",
    "\n",
    "kNN is a type of instance-based learning or lazy learning. Lazy learning means it does not require any training data points for model generation. All training data will be used in the testing phase. This makes training faster and testing slower and costlier. So, the testing phase requires more time and memory resources.\n",
    "\n",
    "In kNN, the neighbours are taken from a set of objects for which the class or the object property value is known. This can be thought of as the training set for the kNN algorithm, though no explicit training step is required. In both classification and regression kNN algorithm, we can assign weight to the contributions of the neighbours. So, nearest neighbours contribute more to the average than the more distant ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. k Nearest Neighbours intuition\n",
    "\n",
    "\n",
    "The kNN algorithm intuition is very simple to understand. It simply calculates the distance between a sample data point and all the other training data points. The distance can be Euclidean distance or Manhattan distance. Then, it selects the k nearest data points where k can be any integer. Finally, it assigns the sample data point to the class to which the majority of the k data points belong.\n",
    "\n",
    "\n",
    "Now, we will see kNN algorithm in action. Suppose, we have a dataset with two variables which are classified as `Red` and `Blue`.\n",
    "\n",
    "\n",
    "In kNN algorithm, k is the number of nearest neighbours. Generally, k is an odd number because it helps to decide the majority of the class. When k=1, then the algorithm is known as the nearest neighbour algorithm.\n",
    "\n",
    "Now, we want to classify a new data point `X` into `Blue` class or `Red` class. Suppose the value of k is 3. The kNN algorithm starts by calculating the distance between `X` and all the other data points. It then finds the 3 nearest points with least distance to point `X`. \n",
    "\n",
    "\n",
    "In the final step of the kNN algorithm, we assign the new data point `X` to the majority of the class of the 3 nearest points. If 2 of the 3 nearest points belong to the class `Red` while 1 belong to the class `Blue`, then we classify the new data point  as `Red`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The problem statement\n",
    "\n",
    "\n",
    "In this project, I try to classify the patients suffering from breast cancer. I implement kNN algorithm with Python and Scikit-Learn. \n",
    "\n",
    "\n",
    "To answer the question, I build a kNN classifier to predict whether or not a patient is suffering from breast cancer. I have used the **Breast Cancer Wisconsin (Original) Data Set** downloaded from the UCI Machine Learning Repository for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset description\n",
    "\n",
    "\n",
    "I have used the **Breast Cancer Wisconsin (Original) Data Set** downloaded from the UCI Machine Learning Repository for this project.\n",
    "\n",
    "\n",
    "The data set can be found at the following url:-\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)\n",
    "\n",
    "\n",
    "This dataset contains the patient samples that arrive periodically as Dr. Wolberg reports his clinical cases. \n",
    "\n",
    "\n",
    "The attribute information of this dataset is as follows:-\n",
    "\n",
    "1. Sample code number: id number \n",
    "2. Clump Thickness: 1 - 10 \n",
    "3. Uniformity of Cell Size: 1 - 10 \n",
    "4. Uniformity of Cell Shape: 1 - 10 \n",
    "5. Marginal Adhesion: 1 - 10 \n",
    "6. Single Epithelial Cell Size: 1 - 10 \n",
    "7. Bare Nuclei: 1 - 10 \n",
    "8. Bland Chromatin: 1 - 10 \n",
    "9. Normal Nucleoli: 1 - 10 \n",
    "10. Mitoses: 1 - 10 \n",
    "11. Class: (2 for benign, 4 for malignant)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r'C:\\MSA\\Python classes\\85 hours\\data analysis project assignment\\k-Nearest-Neighbours-Project\\data\\data.csv'\n",
    "\n",
    "df = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploratory data analysis\n",
    "\n",
    "\n",
    "Now, I will explore the data to gain insights about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 33)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 699 instances and 11 attributes in the data set. \n",
    "\n",
    "\n",
    "In the dataset description, it is given that there are 10 attributes and 1 `Class` which is the target variable. So, we have 10 attributes and 1 target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View top 5 rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>radius_mean</td>\n",
       "      <td>texture_mean</td>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>area_mean</td>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>...</td>\n",
       "      <td>texture_worst</td>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>area_worst</td>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>...</td>\n",
       "      <td>26.5</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1            2             3               4          5   \\\n",
       "0        id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean   \n",
       "1    842302          M        17.99         10.38           122.8       1001   \n",
       "2    842517          M        20.57         17.77           132.9       1326   \n",
       "3  84300903          M        19.69         21.25             130       1203   \n",
       "4  84348301          M        11.42         20.38           77.58      386.1   \n",
       "\n",
       "                6                 7               8                    9   \\\n",
       "0  smoothness_mean  compactness_mean  concavity_mean  concave points_mean   \n",
       "1           0.1184            0.2776          0.3001               0.1471   \n",
       "2          0.08474           0.07864          0.0869              0.07017   \n",
       "3           0.1096            0.1599          0.1974               0.1279   \n",
       "4           0.1425            0.2839          0.2414               0.1052   \n",
       "\n",
       "   ...             23               24          25                26  \\\n",
       "0  ...  texture_worst  perimeter_worst  area_worst  smoothness_worst   \n",
       "1  ...          17.33            184.6        2019            0.1622   \n",
       "2  ...          23.41            158.8        1956            0.1238   \n",
       "3  ...          25.53            152.5        1709            0.1444   \n",
       "4  ...           26.5            98.87       567.7            0.2098   \n",
       "\n",
       "                  27               28                    29              30  \\\n",
       "0  compactness_worst  concavity_worst  concave points_worst  symmetry_worst   \n",
       "1             0.6656           0.7119                0.2654          0.4601   \n",
       "2             0.1866           0.2416                 0.186           0.275   \n",
       "3             0.4245           0.4504                 0.243          0.3613   \n",
       "4             0.8663           0.6869                0.2575          0.6638   \n",
       "\n",
       "                        31  32  \n",
       "0  fractal_dimension_worst NaN  \n",
       "1                   0.1189 NaN  \n",
       "2                  0.08902 NaN  \n",
       "3                  0.08758 NaN  \n",
       "4                    0.173 NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[2:,:12]\n",
    "df.drop(df.columns[1],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>843786</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.7</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>844359</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.6</td>\n",
       "      <td>1040</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84458202</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.2</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>844981</td>\n",
       "      <td>13</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.5</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.07389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84501001</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.08243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      2      3      4      5        6       7        8        9   \\\n",
       "6     843786  12.45   15.7  82.57  477.1   0.1278    0.17   0.1578  0.08089   \n",
       "7     844359  18.25  19.98  119.6   1040  0.09463   0.109   0.1127    0.074   \n",
       "8   84458202  13.71  20.83   90.2  577.9   0.1189  0.1645  0.09366  0.05985   \n",
       "9     844981     13  21.82   87.5  519.8   0.1273  0.1932   0.1859  0.09353   \n",
       "10  84501001  12.46  24.04  83.97  475.9   0.1186  0.2396   0.2273  0.08543   \n",
       "\n",
       "        10       11  \n",
       "6   0.2087  0.07613  \n",
       "7   0.1794  0.05742  \n",
       "8   0.2196  0.07451  \n",
       "9    0.235  0.07389  \n",
       "10   0.203  0.08243  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 11)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename column names\n",
    "\n",
    "We can see that the dataset does not have proper column names. The columns are merely labelled as 0,1,2.... and so on. We should give proper names to the columns. I will do it as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Clump_thickness', 'Uniformity_Cell_Size',\n",
       "       'Uniformity_Cell_Shape', 'Marginal_Adhesion',\n",
       "       'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin',\n",
       "       'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Id', 'Clump_thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape', 'Marginal_Adhesion', \n",
    "             'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class']\n",
    "#col_names=['id', 'Clump_thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape', 'Marginal_Adhesion', \n",
    "#             'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class',\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\",\"raw\"]\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column names are renamed. Now, the columns have meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Clump_thickness</th>\n",
       "      <th>Uniformity_Cell_Size</th>\n",
       "      <th>Uniformity_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84458202</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.2</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>844981</td>\n",
       "      <td>13</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.5</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.07389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84501001</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.08243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>845636</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.7</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84610002</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.6</td>\n",
       "      <td>781</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.06082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id Clump_thickness Uniformity_Cell_Size Uniformity_Cell_Shape  \\\n",
       "8   84458202           13.71                20.83                  90.2   \n",
       "9     844981              13                21.82                  87.5   \n",
       "10  84501001           12.46                24.04                 83.97   \n",
       "11    845636           16.02                23.24                 102.7   \n",
       "12  84610002           15.78                17.89                 103.6   \n",
       "\n",
       "   Marginal_Adhesion Single_Epithelial_Cell_Size Bare_Nuclei Bland_Chromatin  \\\n",
       "8              577.9                      0.1189      0.1645         0.09366   \n",
       "9              519.8                      0.1273      0.1932          0.1859   \n",
       "10             475.9                      0.1186      0.2396          0.2273   \n",
       "11             797.8                     0.08206     0.06669         0.03299   \n",
       "12               781                      0.0971      0.1292         0.09954   \n",
       "\n",
       "   Normal_Nucleoli Mitoses    Class  \n",
       "8          0.05985  0.2196  0.07451  \n",
       "9          0.09353   0.235  0.07389  \n",
       "10         0.08543   0.203  0.08243  \n",
       "11         0.03323  0.1528  0.05697  \n",
       "12         0.06606  0.1842  0.06082  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's agian preview the dataset\n",
    "\n",
    "df.head()\n",
    "\n",
    "df=df.iloc[2:,:11]\n",
    "#df=df.loc[:0,9]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop redundant columns\n",
    "\n",
    "\n",
    "We should drop any redundant columns from the dataset which does not have any predictive power. Here, `Id` is the redundant column. So, I will drop it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Clump_thickness Uniformity_Cell_Size Uniformity_Cell_Shape  \\\n",
      "8            13.71                20.83                  90.2   \n",
      "9               13                21.82                  87.5   \n",
      "10           12.46                24.04                 83.97   \n",
      "11           16.02                23.24                 102.7   \n",
      "12           15.78                17.89                 103.6   \n",
      "\n",
      "   Marginal_Adhesion Single_Epithelial_Cell_Size  Bare_Nuclei Bland_Chromatin  \\\n",
      "8              577.9                      0.1189      0.16450         0.09366   \n",
      "9              519.8                      0.1273      0.19320          0.1859   \n",
      "10             475.9                      0.1186      0.23960          0.2273   \n",
      "11             797.8                     0.08206      0.06669         0.03299   \n",
      "12               781                      0.0971      0.12920         0.09954   \n",
      "\n",
      "   Normal_Nucleoli Mitoses    Class  \n",
      "8          0.05985  0.2196  1.07451  \n",
      "9          0.09353   0.235  1.07389  \n",
      "10         0.08543   0.203  1.08243  \n",
      "11         0.03323  0.1528  1.05697  \n",
      "12         0.06606  0.1842  1.06082  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MD985B~1.SAK\\AppData\\Local\\Temp/ipykernel_16016/2944787277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# drop Id column from dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4913\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4914\u001b[0m         )\n\u001b[0;32m   4915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "def applyadd1(x):\n",
    "    x=str(x)+1\n",
    "    #df['Class']=str(df['Class'])+1\n",
    "df['Class']=(df['Class'].astype(float))\n",
    "df['Class']=df['Class']+1\n",
    "print(df.head())\n",
    "# drop Id column from dataset\n",
    "\n",
    "df.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summary of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 562 entries, 8 to 569\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Clump_thickness              562 non-null    object \n",
      " 1   Uniformity_Cell_Size         562 non-null    object \n",
      " 2   Uniformity_Cell_Shape        562 non-null    object \n",
      " 3   Marginal_Adhesion            562 non-null    object \n",
      " 4   Single_Epithelial_Cell_Size  562 non-null    object \n",
      " 5   Bare_Nuclei                  562 non-null    float64\n",
      " 6   Bland_Chromatin              562 non-null    object \n",
      " 7   Normal_Nucleoli              562 non-null    object \n",
      " 8   Mitoses                      562 non-null    object \n",
      " 9   Class                        562 non-null    float64\n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 44.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# view summary of dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `Id` column has been removed from the dataset. \n",
    "\n",
    "We can see that there are 9 numerical variables and 1 categorical variable in the dataset. I will check the frequency distribution of values in the variables to confirm the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution of values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.34    4\n",
      "12.77    3\n",
      "11.71    3\n",
      "13       3\n",
      "15.46    3\n",
      "        ..\n",
      "14.03    1\n",
      "9.567    1\n",
      "20.51    1\n",
      "10.95    1\n",
      "7.76     1\n",
      "Name: Clump_thickness, Length: 451, dtype: int64\n",
      "18.22    3\n",
      "17.46    3\n",
      "19.83    3\n",
      "20.52    3\n",
      "18.9     3\n",
      "        ..\n",
      "15.9     1\n",
      "17.39    1\n",
      "17.19    1\n",
      "18.58    1\n",
      "24.54    1\n",
      "Name: Uniformity_Cell_Size, Length: 475, dtype: int64\n",
      "87.76    3\n",
      "134.7    3\n",
      "82.61    3\n",
      "152.1    2\n",
      "82.69    2\n",
      "        ..\n",
      "158.9    1\n",
      "115.1    1\n",
      "78.54    1\n",
      "94.49    1\n",
      "47.92    1\n",
      "Name: Uniformity_Cell_Shape, Length: 517, dtype: int64\n",
      "512.2    3\n",
      "641.2    2\n",
      "575.3    2\n",
      "399.8    2\n",
      "716.6    2\n",
      "        ..\n",
      "588.9    1\n",
      "516.4    1\n",
      "671.4    1\n",
      "477.4    1\n",
      "181      1\n",
      "Name: Marginal_Adhesion, Length: 532, dtype: int64\n",
      "0.1007     5\n",
      "0.115      4\n",
      "0.1054     4\n",
      "0.1075     4\n",
      "0.08511    3\n",
      "          ..\n",
      "0.0909     1\n",
      "0.08182    1\n",
      "0.1002     1\n",
      "0.08876    1\n",
      "0.05263    1\n",
      "Name: Single_Epithelial_Cell_Size, Length: 470, dtype: int64\n",
      "0.12060    3\n",
      "0.11470    3\n",
      "0.09509    2\n",
      "0.03834    2\n",
      "0.11170    2\n",
      "          ..\n",
      "0.24130    1\n",
      "0.07253    1\n",
      "0.05562    1\n",
      "0.06141    1\n",
      "0.04362    1\n",
      "Name: Bare_Nuclei, Length: 532, dtype: int64\n",
      "0           13\n",
      "0.1204       3\n",
      "0.2417       2\n",
      "0.1085       2\n",
      "0.1103       2\n",
      "            ..\n",
      "0.001597     1\n",
      "0.05375      1\n",
      "0.06181      1\n",
      "0.06593      1\n",
      "0.3514       1\n",
      "Name: Bland_Chromatin, Length: 531, dtype: int64\n",
      "0           13\n",
      "0.02864      3\n",
      "0.05252      2\n",
      "0.02377      2\n",
      "0.01924      2\n",
      "            ..\n",
      "0.03239      1\n",
      "0.05814      1\n",
      "0.002404     1\n",
      "0.03263      1\n",
      "0.152        1\n",
      "Name: Normal_Nucleoli, Length: 537, dtype: int64\n",
      "0.1769    4\n",
      "0.1893    4\n",
      "0.1714    4\n",
      "0.1601    4\n",
      "0.1717    4\n",
      "         ..\n",
      "0.1594    1\n",
      "0.2251    1\n",
      "0.22      1\n",
      "0.1979    1\n",
      "0.1587    1\n",
      "Name: Mitoses, Length: 428, dtype: int64\n",
      "1.05913    3\n",
      "1.06782    3\n",
      "1.06113    3\n",
      "1.05907    3\n",
      "1.06331    2\n",
      "          ..\n",
      "1.06217    1\n",
      "1.07398    1\n",
      "1.05770    1\n",
      "1.06133    1\n",
      "1.07016    1\n",
      "Name: Class, Length: 494, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for var in df.columns:\n",
    "    \n",
    "    print(df[var].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of values shows that data type of `Bare_Nuclei` is of type integer. But the summary of the dataframe shows that it is type object. So, I will explicitly convert its data type to integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data type of Bare_Nuclei to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bare_Nuclei'] = pd.to_numeric(df['Bare_Nuclei'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data types of columns of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                 object\n",
       "Uniformity_Cell_Size            object\n",
       "Uniformity_Cell_Shape           object\n",
       "Marginal_Adhesion               object\n",
       "Single_Epithelial_Cell_Size     object\n",
       "Bare_Nuclei                    float64\n",
       "Bland_Chromatin                 object\n",
       "Normal_Nucleoli                 object\n",
       "Mitoses                         object\n",
       "Class                          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that all the columns of the dataframe are of type numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of variables\n",
    "\n",
    "\n",
    "- There are 10 numerical variables in the dataset.\n",
    "\n",
    "\n",
    "- All of the variables are of discrete type.\n",
    "\n",
    "\n",
    "- Out of all the 10 variables, the first 9 variables are feature variables and last variable `Class` is the target variable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore problems within variables\n",
    "\n",
    "\n",
    "Now, I will explore problems within variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                0\n",
       "Uniformity_Cell_Size           0\n",
       "Uniformity_Cell_Shape          0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in variables\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `Bare_Nuclei` column contains missing values. We need to dig deeper to find the frequency distribution of \n",
    "values of `Bare_Nuclei`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                0\n",
       "Uniformity_Cell_Size           0\n",
       "Uniformity_Cell_Shape          0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check `na` values in the dataframe\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `Bare_Nuclei` column contains 16 `nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12060    3\n",
       "0.11470    3\n",
       "0.09509    2\n",
       "0.03834    2\n",
       "0.11170    2\n",
       "          ..\n",
       "0.24130    1\n",
       "0.07253    1\n",
       "0.05562    1\n",
       "0.06141    1\n",
       "0.04362    1\n",
       "Name: Bare_Nuclei, Length: 532, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check frequency distribution of `Bare_Nuclei` column\n",
    "\n",
    "df['Bare_Nuclei'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1645 , 0.1932 , 0.2396 , 0.06669, 0.1292 , 0.2458 , 0.1002 ,\n",
       "       0.2293 , 0.1595 , 0.072  , 0.2022 , 0.1027 , 0.08129, 0.127  ,\n",
       "       0.06492, 0.2135 , 0.1022 , 0.1457 , 0.2276 , 0.1868 , 0.1066 ,\n",
       "       0.1697 , 0.1157 , 0.1887 , 0.1516 , 0.1496 , 0.1719 , 0.1559 ,\n",
       "       0.1336 , 0.1098 , 0.03766, 0.05131, 0.1255 , 0.06031, 0.1218 ,\n",
       "       0.219  , 0.1436 , 0.1047 , 0.1686 , 0.05943, 0.1231 , 0.09092,\n",
       "       0.07698, 0.04966, 0.06059, 0.04751, 0.1485 , 0.07081, 0.05473,\n",
       "       0.1267 , 0.1365 , 0.03789, 0.05272, 0.08061, 0.08963, 0.2008 ,\n",
       "       0.08751, 0.1262 , 0.1479 , 0.07773, 0.04701, 0.1413 , 0.05234,\n",
       "       0.1029 , 0.1531 , 0.183  , 0.128  , 0.06829, 0.08424, 0.2146 ,\n",
       "       0.3454 , 0.09546, 0.09362, 0.1535 , 0.2665 , 0.1791 , 0.07165,\n",
       "       0.1053 , 0.09947, 0.1206 , 0.09445, 0.1339 , 0.08606, 0.1036 ,\n",
       "       0.05055, 0.08165, 0.1553 , 0.1313 , 0.07057, 0.05301, 0.07525,\n",
       "       0.1141 , 0.08511, 0.07568, 0.04038, 0.09697, 0.08578, 0.1765 ,\n",
       "       0.1017 , 0.06815, 0.2768 , 0.06575, 0.08404, 0.1209 , 0.2233 ,\n",
       "       0.1303 , 0.08201, 0.07849, 0.1243 , 0.1649 , 0.1752 , 0.06722,\n",
       "       0.06685, 0.11   , 0.2867 , 0.1099 , 0.07325, 0.06136, 0.07862,\n",
       "       0.08028, 0.1807 , 0.1589 , 0.09509, 0.1223 , 0.1284 , 0.09462,\n",
       "       0.09709, 0.05761, 0.06095, 0.06889, 0.1305 , 0.1136 , 0.04102,\n",
       "       0.1137 , 0.09486, 0.05139, 0.1296 , 0.17   , 0.1167 , 0.1021 ,\n",
       "       0.06376, 0.07589, 0.1599 , 0.05113, 0.08498, 0.06679, 0.1665 ,\n",
       "       0.07223, 0.05241, 0.03718, 0.1185 , 0.1666 , 0.1015 , 0.1145 ,\n",
       "       0.05352, 0.05736, 0.09182, 0.1603 , 0.07885, 0.06981, 0.06288,\n",
       "       0.1555 , 0.05743, 0.04302, 0.04276, 0.1294 , 0.1556 , 0.01938,\n",
       "       0.03774, 0.1914 , 0.2832 , 0.08799, 0.08155, 0.1052 , 0.04695,\n",
       "       0.08468, 0.06141, 0.05562, 0.07253, 0.2413 , 0.06601, 0.02344,\n",
       "       0.1353 , 0.198  , 0.05366, 0.08642, 0.1428 , 0.08087, 0.1198 ,\n",
       "       0.2084 , 0.1768 , 0.1058 , 0.09588, 0.07232, 0.07304, 0.1483 ,\n",
       "       0.0623 , 0.1348 , 0.069  , 0.1146 , 0.1306 , 0.1517 , 0.1154 ,\n",
       "       0.05907, 0.113  , 0.08711, 0.1192 , 0.08502, 0.1204 , 0.04994,\n",
       "       0.07624, 0.07722, 0.1096 , 0.07529, 0.1799 , 0.1572 , 0.03813,\n",
       "       0.03574, 0.1074 , 0.04087, 0.06945, 0.1682 , 0.08348, 0.1039 ,\n",
       "       0.1298 , 0.0663 , 0.03393, 0.1325 , 0.06807, 0.1558 , 0.05971,\n",
       "       0.04524, 0.1346 , 0.07234, 0.07808, 0.1606 , 0.05991, 0.1849 ,\n",
       "       0.1041 , 0.1188 , 0.1279 , 0.2063 , 0.2284 , 0.3114 , 0.1639 ,\n",
       "       0.1088 , 0.0629 , 0.1273 , 0.05616, 0.08995, 0.1143 , 0.1147 ,\n",
       "       0.08259, 0.06219, 0.1289 , 0.02675, 0.07608, 0.1961 , 0.04689,\n",
       "       0.07027, 0.0721 , 0.03872, 0.05884, 0.04052, 0.07688, 0.1453 ,\n",
       "       0.0434 , 0.1442 , 0.1802 , 0.0958 , 0.04216, 0.1011 , 0.03729,\n",
       "       0.1181 , 0.05008, 0.1676 , 0.09823, 0.07943, 0.05642, 0.08393,\n",
       "       0.06221, 0.04721, 0.05914, 0.0522 , 0.06797, 0.1642 , 0.1014 ,\n",
       "       0.1838 , 0.06678, 0.07694, 0.05688, 0.05251, 0.03116, 0.03614,\n",
       "       0.03735, 0.05253, 0.03515, 0.07948, 0.05969, 0.05847, 0.03834,\n",
       "       0.03212, 0.1117 , 0.1972 , 0.03454, 0.1111 , 0.08564, 0.08834,\n",
       "       0.1875 , 0.06545, 0.07664, 0.05306, 0.03892, 0.1319 , 0.1283 ,\n",
       "       0.1371 , 0.1125 , 0.06779, 0.04458, 0.04202, 0.1056 , 0.09965,\n",
       "       0.1402 , 0.07326, 0.1139 , 0.09228, 0.09097, 0.07281, 0.09159,\n",
       "       0.05794, 0.0778 , 0.05886, 0.0363 , 0.2364 , 0.2363 , 0.09769,\n",
       "       0.06064, 0.1038 , 0.1304 , 0.05492, 0.05956, 0.0265 , 0.06373,\n",
       "       0.07952, 0.05696, 0.1131 , 0.1669 , 0.07175, 0.08562, 0.1954 ,\n",
       "       0.1497 , 0.06934, 0.1515 , 0.1076 , 0.06374, 0.1438 , 0.166  ,\n",
       "       0.04726, 0.07548, 0.2154 , 0.07079, 0.1073 , 0.1297 , 0.08575,\n",
       "       0.06636, 0.07823, 0.04831, 0.1114 , 0.1318 , 0.07542, 0.07428,\n",
       "       0.1562 , 0.2087 , 0.09758, 0.05361, 0.08895, 0.04768, 0.06232,\n",
       "       0.2576 , 0.05242, 0.07899, 0.08836, 0.04571, 0.0746 , 0.08501,\n",
       "       0.08316, 0.06526, 0.05313, 0.07804, 0.06053, 0.1025 , 0.04605,\n",
       "       0.0812 , 0.06159, 0.1571 , 0.05978, 0.1836 , 0.1168 , 0.08333,\n",
       "       0.03912, 0.1013 , 0.04522, 0.2225 , 0.1316 , 0.1489 , 0.1389 ,\n",
       "       0.07074, 0.1133 , 0.07883, 0.05895, 0.0633 , 0.05581, 0.1113 ,\n",
       "       0.1109 , 0.06718, 0.04462, 0.1232 , 0.09218, 0.1314 , 0.0889 ,\n",
       "       0.078  , 0.1175 , 0.1064 , 0.09871, 0.0645 , 0.09242, 0.0543 ,\n",
       "       0.07426, 0.08574, 0.05205, 0.05073, 0.04626, 0.111  , 0.1988 ,\n",
       "       0.05223, 0.05855, 0.05994, 0.1089 , 0.05428, 0.2004 , 0.06258,\n",
       "       0.06   , 0.08549, 0.03398, 0.1069 , 0.08269, 0.1108 , 0.05319,\n",
       "       0.08228, 0.1893 , 0.07838, 0.05326, 0.1155 , 0.07957, 0.1299 ,\n",
       "       0.1511 , 0.06698, 0.1448 , 0.09263, 0.07112, 0.052  , 0.06217,\n",
       "       0.04043, 0.05275, 0.08345, 0.1334 , 0.0763 , 0.1317 , 0.1644 ,\n",
       "       0.1364 , 0.1681 , 0.1085 , 0.1275 , 0.2239 , 0.2204 , 0.1152 ,\n",
       "       0.1071 , 0.06712, 0.187  , 0.09661, 0.05016, 0.1469 , 0.08918,\n",
       "       0.08597, 0.08499, 0.1248 , 0.131  , 0.1661 , 0.1225 , 0.2106 ,\n",
       "       0.04413, 0.107  , 0.08419, 0.07632, 0.1138 , 0.06307, 0.09755,\n",
       "       0.09009, 0.09713, 0.09453, 0.07255, 0.09752, 0.1739 , 0.1552 ,\n",
       "       0.04878, 0.1199 , 0.112  , 0.123  , 0.07214, 0.06877, 0.1018 ,\n",
       "       0.06747, 0.08066, 0.0503 , 0.06602, 0.04227, 0.08194, 0.04234,\n",
       "       0.05605, 0.05824, 0.07658, 0.07504, 0.04971, 0.133  , 0.1126 ,\n",
       "       0.03558, 0.2236 , 0.1159 , 0.1034 , 0.1023 , 0.277  , 0.04362])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique values in `Bare_Nuclei` column\n",
    "\n",
    "df['Bare_Nuclei'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are `nan` values in the `Bare_Nuclei` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan values in `Bare_Nuclei` column\n",
    "\n",
    "df['Bare_Nuclei'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 16 `nan` values in the dataset. I will impute missing values after dividing the dataset into training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check frequency distribution of target variable `Class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.05913    3\n",
       "1.06782    3\n",
       "1.06113    3\n",
       "1.05907    3\n",
       "1.06331    2\n",
       "          ..\n",
       "1.06217    1\n",
       "1.07398    1\n",
       "1.05770    1\n",
       "1.06133    1\n",
       "1.07016    1\n",
       "Name: Class, Length: 494, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view frequency distribution of values in `Class` variable\n",
    "\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check  percentage of frequency distribution of `Class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.05913    0.005338\n",
       "1.06782    0.005338\n",
       "1.06113    0.005338\n",
       "1.05907    0.005338\n",
       "1.06331    0.003559\n",
       "             ...   \n",
       "1.06217    0.001779\n",
       "1.07398    0.001779\n",
       "1.05770    0.001779\n",
       "1.06133    0.001779\n",
       "1.07016    0.001779\n",
       "Name: Class, Length: 494, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view percentage of frequency distribution of values in `Class` variable\n",
    "\n",
    "df['Class'].value_counts()/np.float(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `Class` variable contains 2 class labels - `2` and `4`. `2` stands for benign and `4` stands for malignant cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers in numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Bare_Nuclei   Class\n",
      "count       562.00  562.00\n",
      "mean          0.10    1.06\n",
      "std           0.05    0.01\n",
      "min           0.02    1.05\n",
      "25%           0.06    1.06\n",
      "50%           0.09    1.06\n",
      "75%           0.13    1.07\n",
      "max           0.35    1.10\n"
     ]
    }
   ],
   "source": [
    "# view summary statistics in numerical variables\n",
    "\n",
    "print(round(df.describe(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN algorithm is robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Visualization\n",
    "\n",
    "\n",
    "Now, we have a basic understanding of our data. I will supplement it with some data visualization to get better understanding\n",
    "of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distribution of variables\n",
    "\n",
    "\n",
    "Now, I will plot the histograms to check variable distributions to find out if they are normal or skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1800 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histograms of the variables\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize']=(30,25)\n",
    "\n",
    "df.plot(kind='hist', bins=10, subplots=True, layout=(5,2), sharex=False, sharey=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the variables in the dataset are positively skewed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating correlation coefficients\n",
    "\n",
    "Our dataset is very small. So, we can compute the standard correlation coefficient (also called Pearson's r) between every pair of attributes. We can compute it using the `df.corr()` method as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable is `Class`. So, we should check how each attribute correlates with the `Class` variable. We can do it as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class          1.000000\n",
       "Bare_Nuclei    0.548417\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation['Class'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "- The correlation coefficient ranges from -1 to +1. \n",
    "\n",
    "- When it is close to +1, this signifies that there is a strong positive correlation. So, we can see that there is a strong positive correlation between `Class` and `Bare_Nuclei`, `Class` and `Uniformity_Cell_Shape`, `Class` and `Uniformity_Cell_Size`.\n",
    "\n",
    "- When it is clsoe to -1, it means that there is a strong negative correlation. When it is close to 0, it means that there is no correlation. \n",
    "\n",
    "- We can see that all the variables are positively correlated with `Class` variable. Some variables are strongly positive correlated while some variables are negatively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover patterns and relationships \n",
    "\n",
    "\n",
    "An important step in EDA is to discover patterns and relationships between variables in the dataset. I will use the seaborn heatmap to explore the patterns and relationships in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Correlation of Attributes with Class variable')\n",
    "a = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=30)           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "\n",
    "From the above correlation heat map, we can conclude that :-\n",
    "\n",
    "1. `Class` is highly positive correlated with `Uniformity_Cell_Size`, `Uniformity_Cell_Shape` and `Bare_Nuclei`. (correlation coefficient = 0.82).\n",
    "\n",
    "2. `Class` is positively correlated with `Clump_thickness`(correlation coefficient=0.72), `Marginal_Adhesion`(correlation coefficient=0.70), `Single_Epithelial_Cell_Size)`(correlation coefficient = 0.68) and `Normal_Nucleoli`(correlation coefficient=0.71).\n",
    "\n",
    "3. `Class` is weekly positive correlated with `Mitoses`(correlation coefficient=0.42).\n",
    "\n",
    "4. The `Mitoses` variable is weekly positive correlated with all the other variables(correlation coefficient < 0.50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis=1)\n",
    "\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((449, 9), (113, 9))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Engineering\n",
    "\n",
    "\n",
    "**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                 object\n",
       "Uniformity_Cell_Size            object\n",
       "Uniformity_Cell_Shape           object\n",
       "Marginal_Adhesion               object\n",
       "Single_Epithelial_Cell_Size     object\n",
       "Bare_Nuclei                    float64\n",
       "Bland_Chromatin                 object\n",
       "Normal_Nucleoli                 object\n",
       "Mitoses                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering missing values in variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                0\n",
       "Uniformity_Cell_Size           0\n",
       "Uniformity_Cell_Shape          0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in numerical variables in X_train\n",
    "\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                0\n",
       "Uniformity_Cell_Size           0\n",
       "Uniformity_Cell_Shape          0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in numerical variables in X_test\n",
    "\n",
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print percentage of missing values in the numerical variables in training set\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().mean()>0:\n",
    "        print(col, round(X_train[col].isnull().mean(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption\n",
    "\n",
    "\n",
    "I assume that the data are missing completely at random (MCAR). There are two methods which can be used to impute missing values. One is mean or median imputation and other one is random sample imputation. When there are outliers in the dataset, we should use median imputation. So, I will use median imputation because median imputation is robust to outliers.\n",
    "\n",
    "\n",
    "I will impute missing values with the appropriate statistical measures of the data, in this case median. Imputation should be done over the training set, and then propagated to the test set. It means that the statistical measures to be used to fill missing values both in train and test set, should be extracted from the train set only. This is to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in X_train and X_test with respective column median in X_train\n",
    "\n",
    "for df1 in [X_train, X_test]:\n",
    "    for col in X_train.columns:\n",
    "        col_median=X_train[col].median()\n",
    "        df1[col].fillna(col_median, inplace=True)           \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                0\n",
       "Uniformity_Cell_Size           0\n",
       "Uniformity_Cell_Shape          0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check again missing values in numerical variables in X_train\n",
    "\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_thickness                0\n",
       "Uniformity_Cell_Size           0\n",
       "Uniformity_Cell_Shape          0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in numerical variables in X_test\n",
    "\n",
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no missing values in X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_thickness</th>\n",
       "      <th>Uniformity_Cell_Size</th>\n",
       "      <th>Uniformity_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>11.6</td>\n",
       "      <td>18.36</td>\n",
       "      <td>73.88</td>\n",
       "      <td>412.7</td>\n",
       "      <td>0.08508</td>\n",
       "      <td>0.05855</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>0.01777</td>\n",
       "      <td>0.1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>13.86</td>\n",
       "      <td>16.93</td>\n",
       "      <td>90.96</td>\n",
       "      <td>578.9</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.09901</td>\n",
       "      <td>0.05602</td>\n",
       "      <td>0.2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>11.41</td>\n",
       "      <td>10.82</td>\n",
       "      <td>73.34</td>\n",
       "      <td>403.3</td>\n",
       "      <td>0.09373</td>\n",
       "      <td>0.06685</td>\n",
       "      <td>0.03512</td>\n",
       "      <td>0.02623</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>17.54</td>\n",
       "      <td>19.32</td>\n",
       "      <td>115.1</td>\n",
       "      <td>951.6</td>\n",
       "      <td>0.08968</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.07488</td>\n",
       "      <td>0.1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.1</td>\n",
       "      <td>26.29</td>\n",
       "      <td>129.1</td>\n",
       "      <td>1132</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.1634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Clump_thickness Uniformity_Cell_Size Uniformity_Cell_Shape  \\\n",
       "464            11.6                18.36                 73.88   \n",
       "216           13.86                16.93                 90.96   \n",
       "121           11.41                10.82                 73.34   \n",
       "202           17.54                19.32                 115.1   \n",
       "84             19.1                26.29                 129.1   \n",
       "\n",
       "    Marginal_Adhesion Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "464             412.7                     0.08508      0.05855   \n",
       "216             578.9                      0.1026      0.15170   \n",
       "121             403.3                     0.09373      0.06685   \n",
       "202             951.6                     0.08968      0.11980   \n",
       "84               1132                      0.1215      0.17910   \n",
       "\n",
       "    Bland_Chromatin Normal_Nucleoli Mitoses  \n",
       "464         0.03367         0.01777  0.1516  \n",
       "216         0.09901         0.05602  0.2106  \n",
       "121         0.03512         0.02623  0.1667  \n",
       "202          0.1036         0.07488  0.1506  \n",
       "84           0.1937          0.1469  0.1634  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_thickness</th>\n",
       "      <th>Uniformity_Cell_Size</th>\n",
       "      <th>Uniformity_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>13.4</td>\n",
       "      <td>20.52</td>\n",
       "      <td>88.64</td>\n",
       "      <td>556.7</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.14690</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.08172</td>\n",
       "      <td>0.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>11.89</td>\n",
       "      <td>21.17</td>\n",
       "      <td>76.39</td>\n",
       "      <td>433.8</td>\n",
       "      <td>0.09773</td>\n",
       "      <td>0.08120</td>\n",
       "      <td>0.02555</td>\n",
       "      <td>0.02179</td>\n",
       "      <td>0.2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>13.8</td>\n",
       "      <td>15.79</td>\n",
       "      <td>90.43</td>\n",
       "      <td>584.1</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.07789</td>\n",
       "      <td>0.05069</td>\n",
       "      <td>0.1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.2</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.02037</td>\n",
       "      <td>0.1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>13.64</td>\n",
       "      <td>15.6</td>\n",
       "      <td>87.38</td>\n",
       "      <td>575.3</td>\n",
       "      <td>0.09423</td>\n",
       "      <td>0.06630</td>\n",
       "      <td>0.04705</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.1717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Clump_thickness Uniformity_Cell_Size Uniformity_Cell_Shape  \\\n",
       "513            13.4                20.52                 88.64   \n",
       "416           11.89                21.17                 76.39   \n",
       "74             13.8                15.79                 90.43   \n",
       "346           10.26                14.71                  66.2   \n",
       "241           13.64                 15.6                 87.38   \n",
       "\n",
       "    Marginal_Adhesion Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "513             556.7                      0.1106      0.14690   \n",
       "416             433.8                     0.09773      0.08120   \n",
       "74              584.1                      0.1007      0.12800   \n",
       "346             321.6                     0.09882      0.09159   \n",
       "241             575.3                     0.09423      0.06630   \n",
       "\n",
       "    Bland_Chromatin Normal_Nucleoli Mitoses  \n",
       "513          0.1445         0.08172  0.2116  \n",
       "416         0.02555         0.02179  0.2019  \n",
       "74          0.07789         0.05069  0.1662  \n",
       "346         0.03581         0.02037  0.1633  \n",
       "241         0.04705         0.03731  0.1717  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have training and testing set ready for model building. Before that, we should map all the feature variables onto the same scale. It is called `feature scaling`. I will do it as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Clump_thickness</th>\n",
       "      <th>Uniformity_Cell_Size</th>\n",
       "      <th>Uniformity_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.691969</td>\n",
       "      <td>-0.221806</td>\n",
       "      <td>-0.719151</td>\n",
       "      <td>-0.666256</td>\n",
       "      <td>-0.786791</td>\n",
       "      <td>-0.870298</td>\n",
       "      <td>-0.677234</td>\n",
       "      <td>-0.786738</td>\n",
       "      <td>-1.059551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.047740</td>\n",
       "      <td>-0.553937</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.191335</td>\n",
       "      <td>0.509173</td>\n",
       "      <td>0.983288</td>\n",
       "      <td>0.159436</td>\n",
       "      <td>0.225487</td>\n",
       "      <td>1.104413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.746130</td>\n",
       "      <td>-1.973044</td>\n",
       "      <td>-0.741512</td>\n",
       "      <td>-0.693116</td>\n",
       "      <td>-0.146946</td>\n",
       "      <td>-0.705137</td>\n",
       "      <td>-0.658667</td>\n",
       "      <td>-0.562858</td>\n",
       "      <td>-0.505723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.001271</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.987727</td>\n",
       "      <td>0.873666</td>\n",
       "      <td>-0.446527</td>\n",
       "      <td>0.348512</td>\n",
       "      <td>0.218210</td>\n",
       "      <td>0.724587</td>\n",
       "      <td>-1.096228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.445960</td>\n",
       "      <td>1.620015</td>\n",
       "      <td>1.567452</td>\n",
       "      <td>1.389164</td>\n",
       "      <td>1.907217</td>\n",
       "      <td>1.528519</td>\n",
       "      <td>1.371929</td>\n",
       "      <td>2.630482</td>\n",
       "      <td>-0.626758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Clump_thickness Uniformity_Cell_Size Uniformity_Cell_Shape  \\\n",
       "0       -0.691969            -0.221806             -0.719151   \n",
       "1       -0.047740            -0.553937             -0.011886   \n",
       "2       -0.746130            -1.973044             -0.741512   \n",
       "3        1.001271             0.001164              0.987727   \n",
       "4        1.445960             1.620015              1.567452   \n",
       "\n",
       "  Marginal_Adhesion Single_Epithelial_Cell_Size Bare_Nuclei Bland_Chromatin  \\\n",
       "0         -0.666256                   -0.786791   -0.870298       -0.677234   \n",
       "1         -0.191335                    0.509173    0.983288        0.159436   \n",
       "2         -0.693116                   -0.146946   -0.705137       -0.658667   \n",
       "3          0.873666                   -0.446527    0.348512        0.218210   \n",
       "4          1.389164                    1.907217    1.528519        1.371929   \n",
       "\n",
       "  Normal_Nucleoli   Mitoses  \n",
       "0       -0.786738 -1.059551  \n",
       "1        0.225487  1.104413  \n",
       "2       -0.562858 -0.505723  \n",
       "3        0.724587 -1.096228  \n",
       "4        2.630482 -0.626758  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have `X_train` dataset ready to be fed into the Logistic Regression classifier. I will do it as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Fit K Neighbours Classifier to the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MD985B~1.SAK\\AppData\\Local\\Temp/ipykernel_16016/1692854522.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# fit the model to the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m                 \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\sunilenv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;34m\"multilabel-sequences\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     ]:\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# import KNeighbors ClaSSifier from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# instantiate the model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Predict the test-set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_proba method\n",
    "\n",
    "\n",
    "**predict_proba** method gives the probabilities for the target variable(2 and 4) in this case, in array form.\n",
    "\n",
    "`2 is for probability of benign cancer` and `4 is for probability of malignant cancer.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of getting output as 2 - benign cancer\n",
    "\n",
    "knn.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of getting output as 4 - malignant cancer\n",
    "\n",
    "knn.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Check the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **y_test** are the true class labels and **y_pred** are the predicted class labels in the test-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the train-set and test-set accuracy\n",
    "\n",
    "\n",
    "Now, I will compare the train-set and test-set accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training-set accuracy score is 0.9821 while the test-set accuracy to be 0.9714. These two values are quite comparable. So, there is no question of overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model accuracy with null accuracy\n",
    "\n",
    "\n",
    "So, the model accuracy is 0.9714. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the **null accuracy**. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "So, we should first check the class distribution in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class distribution in test set\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the occurences of most frequent class is 85. So, we can calculate null accuracy by dividing 85 by total number of occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null accuracy score\n",
    "\n",
    "null_accuracy = (85/(85+55))\n",
    "\n",
    "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model accuracy score is 0.9714 but null accuracy score is 0.6071. So, we can conclude that our K Nearest Neighbors model is doing a very good job in predicting the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Rebuild kNN Classification model using different values of k\n",
    "\n",
    "\n",
    "I have build the kNN classification model using k=3. Now, I will increase the value of k and see its effect on accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild kNN Classification model using k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model with k=5\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "knn_5.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict on the test-set\n",
    "y_pred_5 = knn_5.predict(X_test)\n",
    "\n",
    "\n",
    "print('Model accuracy score with k=5 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild kNN Classification model using k=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model with k=6\n",
    "knn_6 = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "knn_6.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict on the test-set\n",
    "y_pred_6 = knn_6.predict(X_test)\n",
    "\n",
    "\n",
    "print('Model accuracy score with k=6 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild kNN Classification model using k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model with k=7\n",
    "knn_7 = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "knn_7.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict on the test-set\n",
    "y_pred_7 = knn_7.predict(X_test)\n",
    "\n",
    "\n",
    "print('Model accuracy score with k=7 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild kNN Classification model using k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model with k=8\n",
    "knn_8 = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "knn_8.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict on the test-set\n",
    "y_pred_8 = knn_8.predict(X_test)\n",
    "\n",
    "\n",
    "print('Model accuracy score with k=8 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild kNN Classification model using k=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model with k=9\n",
    "knn_9 = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "knn_9.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict on the test-set\n",
    "y_pred_9 = knn_9.predict(X_test)\n",
    "\n",
    "\n",
    "print('Model accuracy score with k=9 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "\n",
    "Our original model accuracy score with k=3 is 0.9714. Now, we can see that we get same accuracy score of 0.9714 with k=5. But, if we increase the value of k further, this would result in enhanced accuracy.\n",
    "\n",
    "\n",
    "With k=6,7,8 we get accuracy score of 0.9786. So, it results in performance improvement.\n",
    "\n",
    "\n",
    "If we increase k to 9, then accuracy decreases again to 0.9714."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n",
    "\n",
    "\n",
    "But, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making. \n",
    "\n",
    "\n",
    "We have another tool called `Confusion matrix` that comes to our rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Confusion matrix\n",
    "\n",
    "\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "\n",
    "**True Positives (TP)** â€“ True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "\n",
    "**True Negatives (TN)** â€“ True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "\n",
    "**False Positives (FP)** â€“ False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
    "\n",
    "\n",
    "\n",
    "**False Negatives (FN)** â€“ False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
    "\n",
    "\n",
    "\n",
    "These four outcomes are summarized in a confusion matrix given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix with k =3 and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows `83 + 53 = 136 correct predictions` and `2 + 2 = 4 incorrect predictions`.\n",
    "\n",
    "\n",
    "In this case, we have\n",
    "\n",
    "\n",
    "- `True Positives` (Actual Positive:1 and Predict Positive:1) - 83\n",
    "\n",
    "\n",
    "- `True Negatives` (Actual Negative:0 and Predict Negative:0) - 53\n",
    "\n",
    "\n",
    "- `False Positives` (Actual Negative:0 but Predict Positive:1) - 2 `(Type I error)`\n",
    "\n",
    "\n",
    "- `False Negatives` (Actual Positive:1 but Predict Negative:0) - 2 `(Type II error)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix with k =7 and slice it into four pieces\n",
    "\n",
    "cm_7 = confusion_matrix(y_test, y_pred_7)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm_7)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm_7[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm_7[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm_7[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm_7[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confusion matrix shows `83 + 54 = 137 correct predictions` and `2 + 1 = 4 incorrect predictions`.\n",
    "\n",
    "\n",
    "In this case, we have\n",
    "\n",
    "\n",
    "- `True Positives` (Actual Positive:1 and Predict Positive:1) - 83\n",
    "\n",
    "\n",
    "- `True Negatives` (Actual Negative:0 and Predict Negative:0) - 54\n",
    "\n",
    "\n",
    "- `False Positives` (Actual Negative:0 but Predict Positive:1) - 2 `(Type I error)`\n",
    "\n",
    "\n",
    "- `False Negatives` (Actual Positive:1 but Predict Negative:0) - 1 `(Type II error)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "\n",
    "So, kNN Classification model with k=7 shows more accurate predictions and less number of errors than k=3 model. Hence, we got performance improvement with k=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Classification metrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "\n",
    "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later.\n",
    "\n",
    "We can print a classification report as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm_7[0,0]\n",
    "TN = cm_7[1,1]\n",
    "FP = cm_7[0,1]\n",
    "FN = cm_7[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification accuracy\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification error\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "\n",
    "**Precision** can be defined as the percentage of correctly predicted positive outcomes out of all the predicted positive outcomes. It can be given as the ratio of true positives (TP) to the sum of true and false positives (TP + FP). \n",
    "\n",
    "\n",
    "So, **Precision** identifies the proportion of correctly predicted positive outcome. It is more concerned with the positive class than the negative class.\n",
    "\n",
    "\n",
    "\n",
    "Mathematically, `precision` can be defined as the ratio of `TP to (TP + FP)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print precision score\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "\n",
    "Recall can be defined as the percentage of correctly predicted positive outcomes out of all the actual positive outcomes.\n",
    "It can be given as the ratio of true positives (TP) to the sum of true positives and false negatives (TP + FN). **Recall** is also called **Sensitivity**.\n",
    "\n",
    "\n",
    "**Recall** identifies the proportion of correctly predicted actual positives.\n",
    "\n",
    "\n",
    "Mathematically, `recall` can be given as the ratio of `TP to (TP + FN)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate\n",
    "\n",
    "\n",
    "**True Positive Rate** is synonymous with **Recall**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_rate = TP / float(TP + FN)\n",
    "\n",
    "\n",
    "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = FP / float(FP + TN)\n",
    "\n",
    "\n",
    "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1-score\n",
    "\n",
    "\n",
    "**f1-score** is the weighted harmonic mean of precision and recall. The best possible **f1-score** would be 1.0 and the worst \n",
    "would be 0.0.  **f1-score** is the harmonic mean of precision and recall. So, **f1-score** is always lower than accuracy measures as they embed precision and recall into their computation. The weighted average of `f1-score` should be used to \n",
    "compare classifier models, not global accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support\n",
    "\n",
    "\n",
    "**Support** is the actual number of occurrences of the class in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the classification threshold level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities of two classes- 2 and 4\n",
    "\n",
    "y_pred_prob = knn.predict_proba(X_test)[0:10]\n",
    "\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "\n",
    "- In each row, the numbers sum to 1.\n",
    "\n",
    "\n",
    "- There are 2 columns which correspond to 2 classes - 2 and 4. \n",
    "\n",
    "\n",
    "    - Class 2 - predicted probability that there is benign cancer.    \n",
    "    \n",
    "    - Class 4 - predicted probability that there is malignant cancer.\n",
    "        \n",
    "    \n",
    "- Importance of predicted probabilities\n",
    "\n",
    "    - We can rank the observations by probability of benign or malignant cancer.\n",
    "\n",
    "\n",
    "- predict_proba process\n",
    "\n",
    "    - Predicts the probabilities    \n",
    "    \n",
    "    - Choose the class with the highest probability    \n",
    "    \n",
    "    \n",
    "- Classification threshold level\n",
    "\n",
    "    - There is a classification threshold level of 0.5.    \n",
    "    \n",
    "    - Class 4 - probability of malignant cancer is predicted if probability > 0.5.    \n",
    "    \n",
    "    - Class 2 - probability of benign cancer is predicted if probability < 0.5.    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the probabilities in dataframe\n",
    "\n",
    "y_pred_prob_df = pd.DataFrame(data=y_pred_prob, columns=['Prob of - benign cancer (2)', 'Prob of - malignant cancer (4)'])\n",
    "\n",
    "y_pred_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities for class 4 - Probability of malignant cancer\n",
    "\n",
    "knn.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 4 - Probability of malignant cancer\n",
    "\n",
    "y_pred_1 = knn.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of predicted probabilities\n",
    "\n",
    "\n",
    "# adjust figure size\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "\n",
    "# adjust the font size \n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "\n",
    "# plot histogram with 10 bins\n",
    "plt.hist(y_pred_1, bins = 10)\n",
    "\n",
    "\n",
    "# set the title of predicted probabilities\n",
    "plt.title('Histogram of predicted probabilities of malignant cancer')\n",
    "\n",
    "\n",
    "# set the x-axis limit\n",
    "plt.xlim(0,1)\n",
    "\n",
    "\n",
    "# set the title\n",
    "plt.xlabel('Predicted probabilities of malignant cancer')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "\n",
    "- We can see that the above histogram is positively skewed.\n",
    "\n",
    "\n",
    "- The first column tell us that there are approximately 80 observations with 0 probability of malignant cancer.\n",
    "\n",
    "\n",
    "- There are few observations with probability > 0.5.\n",
    "\n",
    "\n",
    "- So, these few observations predict that there will be malignant cancer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "\n",
    "- In binary problems, the threshold of 0.5 is used by default to convert predicted probabilities into class predictions.\n",
    "\n",
    "\n",
    "- Threshold can be adjusted to increase sensitivity or specificity. \n",
    "\n",
    "\n",
    "- Sensitivity and specificity have an inverse relationship. Increasing one would always decrease the other and vice versa.\n",
    "\n",
    "\n",
    "- Adjusting the threshold level should be one of the last step you do in the model-building process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. ROC - AUC\n",
    "\n",
    "\n",
    "\n",
    "### ROC Curve\n",
    "\n",
    "\n",
    "Another tool to measure the classification model performance visually is **ROC Curve**. ROC Curve stands for **Receiver Operating Characteristic Curve**. An **ROC Curve** is a plot which shows the performance of a classification model at various \n",
    "classification threshold levels. \n",
    "\n",
    "\n",
    "\n",
    "The **ROC Curve** plots the **True Positive Rate (TPR)** against the **False Positive Rate (FPR)** at various threshold levels.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**True Positive Rate (TPR)** is also called **Recall**. It is defined as the ratio of **TP to (TP + FN)**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**False Positive Rate (FPR)** is defined as the ratio of **FP to (FP + TN)**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various threshold levels. So, an ROC Curve plots TPR vs FPR at different classification threshold levels. If we lower the threshold levels, it may result in more items being classified as positve. It will increase both True Positives (TP) and False Positives (FP).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC Curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_1, pos_label=4)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.title('ROC curve for Breast Cancer kNN classifier')\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve help us to choose a threshold level that balances sensitivity and specificity for a particular context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC  AUC\n",
    "\n",
    "\n",
    "**ROC AUC** stands for **Receiver Operating Characteristic - Area Under Curve**. It is a technique to compare classifier performance. In this technique, we measure the `area under the curve (AUC)`. A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5. \n",
    "\n",
    "\n",
    "So, **ROC AUC** is the percentage of the ROC plot that is underneath the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ROC AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ROC_AUC = roc_auc_score(y_test, y_pred_1)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "\n",
    "- ROC AUC is a single number summary of classifier performance. The higher the value, the better the classifier.\n",
    "\n",
    "- ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in predicting whether it is benign or malignant cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cross-validated ROC AUC \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Cross_validated_ROC_AUC = cross_val_score(knn_7, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "print('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Our Cross Validated ROC AUC is very close to 1. So, we can conclude that, the KNN classifier is indeed a very good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. k-fold Cross Validation\n",
    "\n",
    "\n",
    "In this section, I will apply k-fold Cross Validation technique to improve the model performance. Cross-validation is a statistical method of evaluating generalization performance It is more stable and thorough than using a train-test split to evaluate model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying 10-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(knn_7, X_train, y_train, cv = 10, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize the cross-validation accuracy by calculating its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "\n",
    "- Using the mean cross-validation, we can conclude that we expect the model to be around 96.46 % accurate on average.\n",
    "\n",
    "- If we look at all the 10 scores produced by the 10-fold cross-validation, we can also conclude that there is a relatively high variance in the accuracy between folds, ranging from 100% accuracy to 87.72% accuracy. So, we can conclude that the model is very dependent on the particular folds used for training, but it also be the consequence of the small size of the dataset.\n",
    "\n",
    "- We can see that 10-fold cross-validation accuracy does not result in performance improvement for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Results and conclusion\n",
    "\n",
    "\n",
    "\n",
    "1. In this project, I build a kNN classifier model to classify the patients suffering from breast cancer. The model yields very good performance as indicated by the model accuracy which was found to be 0.9786 with k=7.\n",
    "\n",
    "2. With k=3, the training-set accuracy score is 0.9821 while the test-set accuracy to be 0.9714. These two values are quite comparable. So, there is no question of overfitting. \n",
    "\n",
    "3. I have compared the model accuracy score which is 0.9714 with null accuracy score which is 0.6071. So, we can conclude that our K Nearest Neighbors model is doing a very good job in predicting the class labels.\n",
    "\n",
    "4. Our original model accuracy score with k=3 is 0.9714. Now, we can see that we get same accuracy score of 0.9714 with k=5. But, if we increase the value of k further, this would result in enhanced accuracy. With k=6,7,8 we get accuracy score of 0.9786. So, it results in performance improvement. If we increase k to 9, then accuracy decreases again to 0.9714. So, we can conclude that our optimal value of k is 7.\n",
    "\n",
    "5. kNN Classification model with k=7 shows more accurate predictions and less number of errors than k=3 model. Hence, we got performance improvement with k=7.\n",
    "\n",
    "6. ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in predicting whether it is benign or malignant cancer.\n",
    "\n",
    "7. Using the mean cross-validation, we can conclude that we expect the model to be around 96.46 % accurate on average.\n",
    "\n",
    "8. If we look at all the 10 scores produced by the 10-fold cross-validation, we can also conclude that there is a relatively high variance in the accuracy between folds, ranging from 100% accuracy to 87.72% accuracy. So, we can conclude that the model is very dependent on the particular folds used for training, but it also be the consequence of the small size of the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
