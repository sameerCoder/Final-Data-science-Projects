# -*- coding: utf-8 -*-
"""Heart_failure_logistic_svm_decisiontree QUESTION Only.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17znJOLgGEkYvRowuMXKFAVaJwQsiSkr7

Heart Failure Prediction Using Machine Learning Model

# ToDo Tasks are written in Comment.
# Write the code snippets as suggested in comment.

Dataset Link: https://www.kaggle.com/andrewmvd/heart-failure-clinical-data


or by clicking below link
https://raw.githubusercontent.com/sameerCoder/ML_Datasets/main/heart_failure_clinical_records_dataset.csv

Perform data analysis and use different machine learning algorithms to create a model for predicting mortality 
caused by Heart Failure.

Compare at least 3 different algorithms and show their accuracies with the help of a graph.
"""

import warnings
warnings.simplefilter('ignore')

"""# Importing required libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

"""# Loading the dataset"""

filepath = "https://raw.githubusercontent.com/sameerCoder/ML_Datasets/main/heart_failure_clinical_records_dataset.csv"
data = pd.read_csv(filepath)

"""# Performing EDA"""

# print random 10 lines

# print shape of dataframe.

#print  info of dataframe.

#print describe of dataframe.

"""# Checking the outcome labels"""

# print count of death_event columns

#count plot 'DEATH_EVENT' columns

"""# Checking for null values"""

####

"""# Checking for duplicate rows"""

#####

"""# Checking the distribution of data """

# historical plot

"""# Checking Correlation between Dependent and Independent variables"""

# plotcorrelation heatmap

"""# Outlier Detection and Removal"""

def diagnostic_plot(data, col):
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    sns.distplot(data[col], bins=10)
    plt.title('Histogram')
    
    plt.subplot(1, 3, 2)
    stats.probplot(data[col], dist='norm', fit=True, plot=plt)
    plt.title('Q-Q Plot')
    
    plt.subplot(1, 3, 3)
    sns.boxplot(y=data[col])
    plt.title('Boxplot')
    
    plt.show()

"""Checking the 'age' column """

# detail about age column
# count of age column

# display max and min of age

"""Checking the 'creatinine_phosphokinase' column"""

diagnostic_plot(data, 'creatinine_phosphokinase')

"""Checking the 'ejection_fraction' column"""

diagnostic_plot(data, 'ejection_fraction')

"""Checking the 'platelets' column """

# value counts platelets column and sort it ascending wise.

"""Checking the 'serum_creatinine' column """

diagnostic_plot(data, 'serum_creatinine')

"""Checking the 'serum_sodium' column """

# plot serum_sodium

"""Checking the 'time' column """

# value counts time column and sort it ascending wise.

#plot time

data.shape

"""# Seperating Dependent and Independent variables"""

#X =
#y =

"""# Performing train-test split"""



"""# Scaling the data"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

"""# Checking the Accuracy Scores for 3 different models"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

from sklearn.pipeline import Pipeline
pipeline_lr = Pipeline([('lr', LogisticRegression())])
pipeline_svc = _________________________________________
pipeline_dt = _________________________________________

pipelines = [pipeline_lr, _________________________________________, _________________________________________]
best_acc = 0
best_clf = 0
best_pipeline=""
pipe_dict = {0: 'Logistic Regression', 1: _________________________________________, 2: _________________________________________}

for pipe in pipelines:
    pipe.fit(X_train, y_train)
    
for i, model in enumerate(pipelines):
    print("{} - Test Accuracy: {}".format(pipe_dict[i], model.score(X_test, y_test)))
    
for i, model in enumerate(pipelines):
    if model.score(X_test, y_test)>best_acc:
        best_acc = model.score(X_test, y_test)
        best_pipeline = model
        best_clf = i
print("Classifier with best accuracy is {}". format(pipe_dict[best_clf]))

"""# Importing Performance Metrics for Classification"""

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train, y_train)

print("Train accuracy :{}".format(accuracy_score(y_train, lr.predict(X_train))))
print("Test accuracy :{}".format(accuracy_score(y_test, lr.predict(X_test))))

y_pred_lr = lr.predict(X_test)

y_pred_proba_lr = lr.predict_proba(X_test)[:, 1]

sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True)
plt.title("Confusion Matrix")
plt.show()

print("Classification Report")
print(classification_report(y_test, y_pred_lr))

print("AUC Score: {}".format(roc_auc_score(y_test, y_pred_proba_lr)))

from sklearn.model_selection import cross_val_score
lr_acc = np.mean(cross_val_score(lr, X, y, cv=10, scoring='accuracy')) 
print("Cross Validation accuracy: {}".format(lr_acc))

"""# Support Vector Classifier"""

from sklearn.svm import SVC
svc = SVC(probability=True)
svc.fit(X_train, y_train)

#print"Train accuracy :
#print "Test accuracy :

y_pred_svc = _______________________

y_pred_proba_svc = _____________________________

sns.heatmap_____________________________
plt.title("Confusion Matrix")
plt.show()

print("Classification Report")
_________________________________________

#print "AUC Score:

from sklearn.model_selection import cross_val_score
svc_acc = np.mean(________________________________) 
print("Cross Validation accuracy:

"""# Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

"Train accuracy :
"Test accuracy :

y_pred_dt = ________________________________

y_pred_proba_dt = __________________________

sns.heatmap(confusion_matrix_________________________)
plt.title("Confusion Matrix")
plt.show()

print("Classification Report")

#print "AUC Score:

from sklearn.model_selection import cross_val_score
dt_acc = np.mean(___________________________________) 
print("Cross Validation accuracy

"""# Plotting ROC Curve for all 3 models to compare their accuracies """

fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_proba_lr)
fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_proba_svc)
fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_proba_dt)

plt.style.use('seaborn-whitegrid')
plt.figure(figsize=(8, 5))
plt.plot(fpr_lr, tpr_lr, label="Logistic Regression")
plt.plot(____________________________________________)
plt.plot(__________________________________________)

plt.legend(________________)
plt.title("ROC Curve")
plt.ylabel("TPR")
plt.xlabel("FPR")
plt.show()

"""# Tuning the Hyperparameter 'C' for Logistic Regression"""

from sklearn.model_selection import GridSearchCV

params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}

grid = GridSearchCV(estimator=lr, param_grid=params, cv=10, scoring='accuracy', n_jobs=-1)
grid.fit(X,y)

grid.best_params_

grid.best_score_

"""# Tuning the Hyperparameters 'C', 'kernel' & 'degree' for Support Vector Classifier"""

from sklearn.model_selection import RandomizedSearchCV

params = { 'C': [1, 10, 100, 1000],
           'kernel': ['poly'],
           'degree': [2, 3, 4],
         }

random = RandomizedSearchCV(_______________________________________________)
random.fit(X,y)

random.best_params_

random.best_score_

"""# Tuning the Hyperparameters for Decision Tree"""

from sklearn.model_selection import GridSearchCV

params = { 'max_depth': [3, 4, 5],
           'min_samples_split': [2, 3],
           'min_samples_leaf': [1, 2, 3]}

grid = GridSearchCV(______________________________________________)
grid.fit(X,y)

grid.best_params_

grid.best_score_

"""# Save the best Model"""

import pickle
pickle.dump(_______________________)
model = pickle.load(______________________)
print(model)

# predict the output
y_pred_lr = lr.predict(X_test)

# confusion matrix
print('Confusion matrix of Logistic Regression model: \n', confusion_matrix(y_test, y_pred_lr),'\n')

# show the accuracy
print('Accuracy of Logistic Regression  model = ', format(lr_acc))

"""# Thank you"""